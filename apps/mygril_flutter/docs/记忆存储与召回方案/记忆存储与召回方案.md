# 记忆存储与召回方案（本地稳妥档 + 云端大库）

面向：MyGril Flutter 客户端（Android / Windows 一套代码）  
定位：本方案只写“怎么做”的规则与接口契约，不改代码、不落实现细节。  

---

## 1. 一句话目标

- 本地只保留“重要且常用”的小记忆库（上限 800），保证聊天时召回 < 1 秒。
- 大规模记忆库的召回交给云端；本地更像“随身小本子”。
- 记忆完全自动化：用户不做选择；只有用户需要找回时，未来在“回收站页面”里手动恢复。

---

## 2. 当前现状（为了对齐）

- 项目聊天数据已经在使用 Drift + SQLite（`apps/mygril_flutter/lib/src/core/database/database.dart`）。
- 记忆目前存在独立实现（`apps/mygril_flutter/lib/src/features/memory/repositories/memory_repository.dart`），且与 Drift 体系未对齐（后续实现会统一到 Drift）。
- 记忆入库当前是“AI 总结 → embedding → 入库”，触发点在会话结束 / 每 N 条消息（见 MemoryPlugin / MemoryService）。

> 本文档定义“目标行为”。后续实现时应以 Drift 为最终落地（跨端一致、易备份/同步）。

---

## 2.5 施工总方向（结合当前项目，不写细节）

这一节是“总复习 + 施工入口指路”，让后续真正动工时知道从哪下手、改哪类文件。

### 2.5.1 先对齐“本地存储体系”（避免两套数据库）

当前项目聊天已经统一到 Drift，本方案也要求一套代码多端可用，因此建议：

- 将记忆存储从 `sqflite` 迁移到 Drift 的 `AppDatabase`（同一个 `mygril.db`）。  
  - 入口参考：`apps/mygril_flutter/lib/src/core/database/database.dart`（表定义）  
  - 现状问题点：`apps/mygril_flutter/lib/src/features/memory/repositories/memory_repository.dart` 目前是独立 db（`mygril_memory.db`）且与 Drift 回收站字段不一致
- 建议新增/对齐两张表：
  - `memories`：有效记忆 + 回收站字段（`deleted_at/purge_at`）+ 系统维护字段（`use_count/last_active_at`）  
  - `memory_tombstones`：墓碑列表（幂等、避免重复上传/误复活）

### 2.5.2 先把“召回链路”跑通（topK=3 + 带时间戳）

当前召回入口在 MemoryPlugin：

- 入口：`apps/mygril_flutter/lib/src/features/plugins/memory/memory_plugin.dart` 的 `getSystemPrompt()`
- 召回实现：`apps/mygril_flutter/lib/src/features/memory/services/memory_service.dart` → `MemoryRepository.search()`

落地时只需要确保三件事：

- 能按本方案“候选 300 → 相似度排序 → topK=3”稳定返回
- 命中的记忆自动维护：`use_count += 1`、`last_active_at = now`
- 注入格式固定为：`n天前的对话摘要“...”`（由 `created_at` / `last_active_at` 计算距今时间，摘要文本中尽量包含事件发生时间描述）

### 2.5.3 再把“入库与维护”升级为可管理（不仅新增）

当前入库入口是会话结束触发总结：

- 会话结束触发：`apps/mygril_flutter/lib/src/features/chat/data/session_manager.dart`
- 总结触发：`apps/mygril_flutter/lib/src/features/plugins/memory/memory_plugin.dart` 的 `onSessionEnd()` / `_checkAndTriggerSummarization()`
- 总结与入库：`apps/mygril_flutter/lib/src/features/memory/services/memory_service.dart` 的 `summarizeAndStore()`

建议把“总结 AI 输出”从纯文本摘要，升级为能提供本方案要求的评分与维护指令（但实现阶段可以先做最小闭环）：

- 最小闭环：先让 AI 在摘要时顺便给出 `E/I/P/J`，入库时算出 `importance`
- 核心记忆维护（P=1）：冲突由 AI 直接修改旧记忆内容（括号补丁），以用户最新为准

### 2.5.4 最后接入云同步（按 scope 开关）

项目已有同步框架与回收站语义（聊天/渠道商已在 Drift 中有 `deleted_at/purge_at`），建议复用同一套：

- scope 清单总账：`apps/mygril_flutter/docs/备份与同步方案/同步范围清单.md`
- scope 本地存储：`apps/mygril_flutter/lib/src/core/database/database.dart` 的 `sync_scopes`
- 同步服务入口：`apps/mygril_flutter/lib/src/core/sync/sync_service.dart`（目前主要处理 conversations/messages/providers）

记忆的同步接入建议顺序：

1) 先同步有效记忆（`memory`）  
2) 再同步冗余记忆/回收站（`memory.trash`）+ 墓碑  
3) 勾选了 `memory.trash` 且云端可用时：上传回收站记忆 + 墓碑 → 清空本地回收站（保留墓碑用于幂等）

> 回收站 UI 暂不做：文档已标注留给未来开发。

---

## 3. 固定参数（稳妥档）

- `localMaxMemories = 800`：本地有效记忆（不含回收站）上限。
- `candidateLimit = 300`：每次召回先取候选的上限，再在本地计算相似度。
- `topK = 3`：最终注入对话提示词的记忆条数。
- 回收站保留：`7 天`（超过后物理删除，或云端已接管则仅保留墓碑用于幂等）。

---

## 4. 术语与规则

### 4.1 记忆的两类

- **核心记忆（P=1）**：用户非常明确的喜好/厌恶（习惯、人格）、长期病痛等。  
  - 必入库、需要维护（冲突时更新旧记忆内容）。
  - 不受“时间系数”衰减影响（见《记忆重要性计算》）。
  - 不参与“超过 800 的自动淘汰”。
- **普通记忆（P<1）**：长期计划（P≈0.5）或短期事实（P≈0.1）。

### 4.2 回收站（本地）

- 任何被“自动淘汰/删除/被替换”的记忆先进入回收站，不立刻物理删除。
- 回收站未来会做一个统一页面（所有删除内容都在回收站）。当前阶段只定义数据与规则，不要求 UI。
- 回收站保留 7 天：`deleted_at = now`，`purge_at = now + 7天`。

### 4.3 冗余记忆（云同步语义）

你定义的“冗余记忆”= 回收站记忆（Trash）。

- 用户在云同步设置里可勾选：
  - “记忆”（同步有效记忆）
  - “冗余记忆”（同步回收站记忆，默认关闭）
- 只有两者都允许且云端连接可用时，才会把回收站记忆推上云端并清空本地回收站。

> scope 的具体字符串可先占位：`memory` 与 `memory.trash`（实现时以实际 UI/后端为准）。

---

## 5. 数据结构（目标形态，供实现对齐）

### 5.1 `memories`（有效记忆 + 回收站记忆）

建议字段（对齐项目现有回收站语义）：

- `id`：本地 UUID
- `content`：记忆文本（对话摘要/事实）
- `embedding`：向量（本地轻量检索用；可为空）
- `created_at`：入库时间（总结发生的时间）
- `last_active_at`：最后一次“被注入 topK”的时间（系统维护）
- `use_count`：被注入 topK 的次数（系统维护）
- `persistence_p`：P（0~1，AI 输出）
- `emotion_e`：E（0~1，AI 输出，负面权重大）
- `info_i`：I（0~1，AI 输出）
- `judge_j`：J（0~1，AI 输出，综合兜底）
- `info_importance`：信息重要性（0~1，按公式计算）
- `time_coef`：时间系数（0.8~1，系统计算；P=1 强制 1）
- `importance`：最终重要性（`info_importance * time_coef`）
- 回收站字段：`deleted_at` / `purge_at`
- `is_synced` / `sync_state`：实现云同步时使用（按项目同步框架对齐）

### 5.2 `memory_tombstones`（墓碑列表，用于幂等）

用途：避免回收站重复上传、以及云端/本地的删除一致性。

建议字段：
- `tombstone_id`：UUID
- `memory_id`：对应的记忆 id
- `deleted_at` / `purge_at`
- `reason`：`evicted` / `replaced` / `user_delete` / `conflict_patch` 等
- `cloud_synced_at`：成功上传墓碑到云端的时间（可空）
- `payload_hash`：可选，用于幂等与调试

---

## 6. 召回（聊天时注入 topK=3）

触发时机：用户发送消息，MemoryPlugin 生成 System Prompt 片段。

### 6.1 候选筛选（先粗筛 300 条）

规则（只取有效记忆，不含回收站）：

- 按 `importance` 降序取前 `candidateLimit=300`。
- 若实现阶段需要更稳：可以优先保证核心记忆（P=1）全量进入候选，然后再补齐普通记忆到 300。

### 6.2 相似度排序（本地轻量向量搜索）

- 对候选计算与用户当前消息 embedding 的余弦相似度。
- 取前 `topK=3` 作为“本次召回”。
- 对命中的记忆：`use_count += 1`，`last_active_at = now`（系统维护）。

### 6.3 注入格式（必须带“距今多久”的时间戳）

你要求的最终格式是：

- `n天前的对话摘要“...”`

建议细化为：

- `今天/1天前/3天前/10天前`
- 超过 30 天自动转月：`2个月前`
- 超过 365 天自动转年：`1年前`

最终插入 prompt 的示例（仅示意）：

- `3天前的对话摘要“你不喜欢香菜，吃到会很反感。”`

备注：总结 AI 需要“注意对话中提到的事件发生时间（如果有）”，但不强制做结构化抽取。若对话出现“昨晚/上个月/去年”等描述，可直接体现在摘要文本里。

---

## 7. 入库与维护（会话结束触发，总结 AI 负责管理）

### 7.1 总结 AI 的职责（不是只会新增）

总结 AI（记忆管理 AI）每次处理一段对话，需要输出“对记忆库的操作”，包括：

- 新增：生成 1~N 条新记忆（带 E/I/P/J）
- 维护：对 P=1 的核心记忆做冲突处理与内容更新
- 淘汰建议：当普通记忆明显不再需要时，可建议送入回收站（但重复度判定暂不做自动化）

### 7.2 P=1 冲突维护（由 AI 决策）

规则：

- 如果新对话与某条核心记忆冲突，总结 AI 直接“修改旧记忆内容”，在旧记忆里加括号补丁，并以“用户最新表述为准”。

示例（仅示意）：

- 旧：`你很爱吃辣。`
- 新对话出现：胃炎近期不吃辣  
- AI 维护后：`你很爱吃辣。（2025-12-xx：最近胃炎，暂时不吃辣，以后再观察）`

实现阶段可以选择：
- 只保留一条“被维护后的最终 content”（简单）
- 或额外存一份“修订历史”（便于追溯，未来再做）

---

## 8. 超额淘汰（>800 → 进回收站）

触发点：
- 新增/维护后，统计“有效记忆”条数 > `localMaxMemories=800`。

淘汰规则（默认）：
- 核心记忆（P=1）不参与淘汰。
- 普通记忆按 `importance` 从低到高送入回收站，直到回到 800。
- 重复度极高的自动判定：当前阶段不做（文档保留为未来项）。

---

## 9. 云同步（回收站记忆 + 墓碑幂等）

满足以下条件时：

1) 用户勾选“记忆”同步  
2) 用户勾选“冗余记忆（回收站）”同步（默认关闭）  
3) 云端连接可用

则执行：

- 上传：本地回收站中的所有记忆 + 对应墓碑列表（用于幂等/去重）。
- 清空：本地回收站数据清空（但墓碑列表保留，用于防重复上传）。
- 本地可选保留：只保留一条“云端已接管”的摘要记录（实现时再定具体落点）。

云端不可用或用户未勾选冗余记忆：

- 本地回收站记忆只在本地保留 7 天，超过后物理删除（同时保留墓碑以避免误复活/重复上报）。

---

## 10. 验收清单（做完就算对）

- 聊天时能稳定注入 3 条记忆，并且每条都有“n天前的对话摘要…”
- 记忆库超过 800 后，普通记忆自动进入回收站（7 天内可恢复，未来 UI 做入口）
- P=1 核心记忆不被自动淘汰；发生冲突时由总结 AI 维护旧记忆内容（括号补丁）
- 云同步打开“记忆+冗余记忆”且连上云端时：回收站记忆能上传并清空本地回收站，同时保留墓碑用于幂等

---

## 11. 明确留给未来的事项（本期不做）

- “重复度极高的记忆”自动判定与合并/淘汰（影响因素太多，暂不自动化）
- 回收站页面（统一展示所有删除内容 + 手动恢复）
- 结构化抽取事件发生时间（现在只要求总结 AI 在摘要里尽量体现）
